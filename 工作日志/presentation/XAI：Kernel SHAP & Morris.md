**Table of Contents**

-  [[#Kernel SHAP|Kernel SHAP]]
	-   [[#局部解释模型|局部解释模型]]
	-   [[#Additive feature attribution methods|Additive feature attribution methods]]
	-   [[#LIME|LIME]]
	-   [[#SHAP (SHapley Additive exPlanation) approach for results interpretation|SHAP (SHapley Additive exPlanation) approach for results interpretation]]
		-   [[#举例说明|举例说明]]
		-  [[#Shapley|Shapley]]
		-   [[#TreeSHAP|TreeSHAP]]
		-   [[#Kernel  SHAP|Kernel  SHAP]]
		-  [[#Kernel  SHAP#举例|举例]]
		-   [[#Kernel  SHAP#SHAP 与 LIME|SHAP 与 LIME]]
		-  [[#Kernel  SHAP#Kernel SHAP公式说明|Kernel SHAP公式说明]]


-  [[#Morris(Sensitivity Analysis)|Morris(Sensitivity Analysis)]]
	-  [[#SA (Sensitivity Analysis)|SA (Sensitivity Analysis)]]
	-  [[#Morris|Morris]]

----

## Kernel SHAP

###### 局部解释模型
- 解释模型通常使用简化后的输入x'，通过映射函数$x = h_x(x')$映射到原始输入。
- **局部方法**试图确保当z' ≈ x'时，$g(z') ≈ f(h_x(z'))$。尽管$x'$可能包含比$x$更少的信息，但$h_x$是特定于当前输入x的，因此$h_x(x')=x$。
	-  简化的输入  $x'$ ：对输入的复杂特征进行解释时，只考虑每个特征对输出的贡献，而忽略其他特征之间的交互作用
	- 例如，对于文本数据，可以使用词袋模型(Bag-of-word)将文本转换为向量表示，然后将这些向量转换为二进制表示（例如，1表示单词出现在文本中，0表示单词未出现）。
	- 对于图像数据，可以使用超像素分割算法将图像分成多个块，并将每个块表示为二进制值（例如，1表示块存在，0表示不存在）。
	- 在这些示例中，简化的输入特征是二进制的，数量较少，比原始输入数据更容易解释和理解。
>下面公式中，f代表**需要解释的模型**，g代表**模型的解释模型**

---
##### Additive feature attribution methods
- **加性特征归因方法**是下面构建解释模型的基础：
$$
g(z') = \phi_0 + \sum_{i=1}^{M} \phi_i z_i'\quad \text{(1)}
$$
- 其中，$z' ∈ \{0, 1\}^M$，M是简化的**输入特征的数量**
	- 即每个输入特征都用$\{0,1\}$表示
	- $\phi_i ∈ R$ ，表示**每个特征对预测结果的影响程度**
与公式(1)定义相匹配的解释模型的方法将**每个特征的影响程度$\phi_i$归因于每个特征**，而**将所有特征归因的效应求和可以近似原始模型的输出$f(x)$**
- 这个公式的意义是，M个特征，每个特征对预测结果产生的影响是$\phi_i$ ,$\phi_0$则类似于残差项的影响程度，是由于M个特征的综合影响而导致模型最终预测结果。

---
##### LIME
LIME是加性的特征归因方法之一，该方法使用的**局部线性解释模型**完全遵循公式(1)。
- LIME将简化的输入$x'$称为“可解释输入”，而**映射$x=h_x(x')$将可解释输入的二进制向量转换为原始输入空间**。
- **不同类型的$h_x$映射用于不同的输入空间**。
	- 例如，对于词袋文本特征，$h_x$将1或0（存在或不存在）的向量转换为原始词数，如果简化输入为1，则为1，如果简化输入为0，则为0。
	- 对于图像，$h_x$将图像视为一组超像素，将1映射为保留超像素的原始值，将0映射为用相邻像素的平均值替换超像素（这意味着它被视为缺失值）。


LIME使用以下目标函数计算特征影响程度$\phi$:
$$
ξ = \underset{g \in G}{arg{}\ min} L(f, g, π_{x'} ) + Ω(g) \quad \text{(2)}
$$
- 其中，$L$是**针对简化输入空间中*一组样本*的损失函数**。
	- 针对一组简化后的样本值，通过最小化实际预测值与解释模型预测值之间的差异的平方和，得到每一组样本的损失函数L。
- 局部核$π_x'$对损失函数计算加权，为简化输入空间的每个样本分配权重，来确保解释模型$g(z')$对于原始模型$f(h_x(z'))$的准确性。
- $Ω$是对解释模型$g$复杂度的惩罚项。
- 由于在LIME中解释模型$g$遵循公式1并且$L$是平方损失，因此可以使用惩罚线性回归来计算公式(2)（: 特征影响程度）

- 为了计算公式(2)，我们首先可以将$g(z′)$表示为基函数$\phi(z′)$的线性组合:
  - $$
g(z') = \sum_{j=1}^{M}\beta_j\phi_j(z')
$$
  - 其中$\beta_j$是回归系数，$\phi_j(z')$是基函数。然后我们可以最小化以下目标函数:
  -  
 $$
	\hat{\beta} = \underset{\beta}{arg\ min}\left[ \sum_{i=1}^n \left(y_i-\sum_{j=1}^M \beta_j \phi_j(z'_i)^2 + \lambda \sum_{j=1}^M |\beta_j| \right) \right]
$$
  - 其中$y_i = f(x_i)$是原始模型对第$i$个实例的预测，$\lambda$是控制惩罚项$\sum_{j=1}^M |\beta_j|$强度的正则化参数。惩罚项用于防止过拟合，并使得归系数尽可能小。
  - 结果系数$\hat{\beta}$然后可以使用以下公式来计算特征重要性程度（特征对目标值的影响程度）:
  - $$
\phi_j(z') = {1\over{n}}\sum_{i=1}^n \hat{\beta}_j\phi_j(z'_i)
$$ 
-  在公式2中，$L$是针对简化输入空间中一组样本的损失函数，而$\hat{\beta}$是使用惩罚线性回归计算出来的权重系数。
   - 公式2的目标是最小化$g$的复杂度$Ω(g)$和损失$L$。
   - 因此，我们可以将$\hat{\beta}$视为特征对目标值的影响程度的权重，并使用公式来计算每个特征的重要性$\phi_j$。 
   - 具体而言，$\hat{\beta}_j$表示特征$j$的权重系数，$\phi_j(z'_i)$是样本$i$在生成简化样本$x'$时，对特征$j$的影响程度。 所以，$\hat{\beta}_j\phi_j(z'_i)$表示样本$i$对特征$j$的重要性程度，然后我们取所有样本重要性的平均值，即可计算出所有样本中特征$j$的平均重要性程度$\phi_j$。
   - 其中$\phi_j$是特征$j$的重要性分数，$\phi_j(z'_i)$为$i$实例的$j$基函数的值

总结一下LIME的实现：
1.  将简化输入$x'$转换为原始输入$x=h_x(x')$。
2.  对于给定的样本，计算在$x'$上的局部权重核$π_{x'}$。
3.  使用加权的线性回归模型来拟合局部模型$g$，使得在给定权重核下的损失函数$L(f,g,π_{x'})$最小化。
4.  添加一个正则化项$Ω(g)$来惩罚复杂度。
5.  使用交叉验证或其他方法来选择最优的正则化参数。
6.  最后得到的局部模型$g$的输出即为$\phi(x)$，即特征$x$的重要性分数。
#### SHAP (SHapley Additive exPlanation) approach for results interpretation
- 机器学习在预测时间序列数据方面具有巨大的潜力。但研究人员通常不会解释他们的预测，这是采用机器学习的障碍。
- 为了克服这个问题，Lundberg和Lee(2017)提出了一种SHAP方法来解释不同技术的预测，包括LightGBM、NGBoost、CatBoost、XGBoost和Scikit-learn树模型。
- SHAP帮助用户解释复杂模型的预测。Shapley最初于1953年提出，它基于博弈论(Shapley, 1953)。它允许我们通过计算每个特征对预测的影响来解释特定输入(X)的预测。Shapley估计值的计算方法如下:
$$
\hat{\phi}_j = {{1}\over{K}}\sum_{k=1}^{K}{( \hat{g}\left(x_{+j}^{m}\right)-\hat{g}\left(x_{-j}^m\right))}
$$

Shapley值是一种用于**衡量特征对于模型预测的贡献程度**的方法。
Shapley值的核心思想是：
- 对于一个特征，它对于模型预测的贡献程度指 ：
	在所有可能的特征子集中，它被添加到这些子集中后，所造成的模型预测变化值的平均值。

---
#### 举例说明
假设以下情形：已经训练了一个机器学习模型来预测公寓价格，分别有park、size、floor、car四个特征。某个面积为50平方米（size=50）、位于二楼（floor=2nd）、附近有一个公园（park=nearby）、禁止猫咪（cat=banned）的公寓，它预测价格为300,000欧元，你需要解释这个预测，即每个特征是如何促进预测的？当所有公寓的平均预测为310,000欧元时，与平均预测相比，每个特征值对预测的贡献是多少？

假设park=nearby，cat=banned，size=50，floor=2nd的特征值共同实现了300,000欧元的预测。我们的目标是解释实际预测（300,000欧元）和平均预测（310,000欧元）之间的差异：-10,000欧元。
答案可能是：park=nearby贡献了30,000欧元，size=50贡献了10,000欧元，floor=2nd贡献了0欧元，cat=banned贡献了-50,000欧元，这些贡献加起来为-10,000欧元，即最终预测减去平均预测的公寓价格。

**那实际上我们应该如何计算目标公寓实例（park=nearby，cat=banned，size=50，floor=2nd）其中一个特征的Shapley值？**

**Shapley值是所有可能子集集合中特征值的平均边际贡献**。
以该公寓实例的cat=banned为例，在下图中，我们估计了cat=banned特征值被添加到park=nearby和size=50的联盟后的贡献。
- 第一步，我们从数据中随机抽取另一个公寓（*该公寓floor=1st，cat=allowed，park和size可以不关注*），
- 使用该公寓自己的floor特征值1st，模拟出park=nearby，size=50和cat=banned的联盟，这个组合（*floor=1st，park=nearby，size=50和cat=banned*）预测公寓的价格刚好为310,000欧元。
- 第二步，我们从联盟中删除*cat=banned*，然后用该公寓的cat特征值allowed替代，我们用这个组合（*floor=1st，park=nearby，size=50和cat=allowed*）预测公寓的价格为320,000欧元。

![](https://pic1.zhimg.com/80/v2-13f5f6c41152bba5fa5ed8728e43f62c_720w.webp)
            (假设我们改变其中一个特征后，理论目标值就变为平均值)

- 可以看到，基于我们随机抽取的公寓，我们预测park=nearby，size=50和cat=banned的联盟的公寓价格为310,000欧元，预测park=nearby和size=50的联盟的公寓价格为320,000欧元，那cat=banned的贡献是310,000欧元 - 320,000欧元 = -10,000欧元。
- 由于该公寓充当cat和floor特征值的“供体（donor）”，所以*这个估计值取决于随机抽取的公寓的值*，如果我们**重复这个抽样步骤并取贡献的平均，我们将得到更好的特征贡献值估计**。

上面只介绍了park=nearby和size=50集合的贡献，而Shapley值是所有可能联盟的所有边际贡献的平均值，所以我们应该对所有可能的联盟重复这个计算。计算时间随着特征的数量和每个联盟中抽样的实例数量呈指数增长。下面是计算目标公寓的**cat=banned**的Shapley值的所有特征值（除cat外其他特征所构成的子集）集合：

-   空集合
-   park=nearby
-   size=50
-   floor=2nd
-   park=nearby 和 size=50
-   park=nearby 和 floor=2nd
-   size=50 和floor=2nd
-   park=nearby 和size=50 和floor=2nd.

对于这些联盟中的每一个，我们**计算带有和不带有cat=banned特征值的预测公寓价格，并计算差值来获得边际贡献，Shapley值是边际贡献的（加权）平均值**，我们用来自数据集的随机公寓的特征值替换不在联盟中的特征的特征值，以从机器学习模型获得预测。如果我们估计所有特征值的Shapley值，我们将得到特征值中预测的完整分布（减去平均值）。

具体来说，Shapley值的计算方法是通过**计算所有可能特征子集对于模型预测的影响**来进行的。
- 在这个计算过程中，**每个特征子集被视为一个“玩家联盟”，每个特征被视为一个“玩家”，而每个特征在一个特征子集中的出现被视为一个“合作行为”。**

---
#### Shapley
计算Shapley值的过程中，首先需要确定每个特征子集的“贡献”，即该特征子集中每个特征的贡献值。然后，通过将每个特征子集的“贡献”加权平均，就可以得到每个特征的Shapley值。
$$
\hat{\phi}_j = {{1}\over{K}}\sum_{k=1}^{K}{( \hat{g}\left(x_{+j}^{m}\right)-\hat{g}\left(x_{-j}^m\right))}
$$
上述公式中，
- $\hat{\phi}_j$ 表示特征 $j$ 的Shapley值的估计值，
- $\hat{g}\left(x_{+j}^{m}\right)$ 表示将特征 $j$ 的值设置为 $x_{+j}^{m}$ 时模型的预测值，
- $\hat{g}\left(x_{-j}^m\right)$ 表示将特征 $j$ 的值从原始的输入 $x$ 中删除后，模型的预测值。
- $K$ 表示采样的次数。

具体地，计算 $\hat{\phi}_j$ 的过程中，
- 对于每一次采样 $k$，
- 需要从输入 $x$ 中**随机选择一些特征**，并将这些特征的值设置为 $x_{+j}^{m}$
	- $x_{+j}^{m}$ 表示将样本 $m$ 中除了第 $j$ 个特征以外的所有特征值保持不变，而将第 $j$ 个特征的值设置为**训练集中特征j的随机值** ，从而得到的新样本。
- 然后将特征 $j$ 的值设置为原始输入 $x$ 中的值。
- 得到一个新的输入 $\tilde{x}_k$。
- 然后，计算模型在输入 $\tilde{x}_k$ 上的预测值 $\hat{g}(\tilde{x}_k)$，预测新样本k的模型预测值

- 接着，需要对所有采样得到的预测值进行平均，并减去**特征 $j$ 不出现时的平均预测值**，从而得到 $\hat{\phi}_j$ 的估计值。
	
	这样可以将第 $j$ 个特征在样本 $m$ 中的影响单独拎出来，从而更好地衡量该特征对于模型预测的贡献。

---
#### TreeSHAP
在Lundberg等人(2018)的工作中，TreeSHAP是一种计算**决策树模型**中**特征相互作用值**的方法。特征相互作用值指的是**两个特征在一起出现时对于模型预测的贡献程度**。
   - (组合特征对于特征预测的贡献程度)

具体来说，根据Lundberg等人(2018)的方法，特征 $i$ 和特征 $j$ 的相互作用值可以通过对所有**包含特征 $i$ 和特征 $j$ 的特征子集**进行**加权求和**来进行估计。其中，每个特征子集被视为一个“玩家联盟”，每个特征被视为一个“玩家”，而每个特征在一个特征子集中的出现被视为一个“合作行为”。

	- Lundberg, S. M., Erion, G. G., & Lee, S. -I. (2018). Consistent Individualized Feature Attribution for Tree Ensembles. 2.

具体地，根据Lundberg等人(2018)的公式，特征 $i$ 和特征 $j$ 的相互作用值 $\phi_{i,j}$ 可以通过以下方式进行计算：
1.  
  - 对于**所有特征子集** $S\subseteq N\{i,j\}$
  计算 $\delta_{i,j}(S)$ 
   - $\delta_{i,j}(S)$代表有{i,j}时的预测值和无特征值{i,j}进行模型预测的差：
$$
\delta_{ij}(S) = f_x(S ∪ \{i, j\}) − f_x(S ∪ \{i\} )− f_x(S ∪ \{j\}) + f_x(S)
$$
其中  $(i≠j)$，$f_x(S)$ 表示模型在**特征子集 $S$ 上的预测值**

- $f_x(S)$ 表示只考虑特征子集 $S$ 时得到的模型输出值，
- $f_x(S ∪ {i})$、$f_x(S ∪ {j})$ 和 $f_x(S ∪ {i, j})$ 则表示加上特征 $i$、加上特征 $j$ 和加上特征 $i$ 和 $j$ 后得到的新样本的模型输出值。

因此，$f_x(S \cup {i})$ 的意义是包含特征 $i$ 和 $S$ 中其它特征的子集对应的模型预测值。这个值与 $\delta_{ij}(S)$ 中的其它三个值一样，都是为了计算特征 $i$ 和特征 $j$ 的交互作用值而引入的。
2.  对于**每个特征子集 $S$**，计算**该特征子集**对于**相互作用值**的贡献：
$$
\phi_{i,j} = \sum_{S\subseteq N\{i,j\}}\frac{|S|!(M-|S|-2)!}{2(M-1)!}\delta_{i,j}(S)
$$
其中，$M$ 表示**特征的总数**，$|S|$ 表示**特征子集 $S$ 中包含的特征数**。
- $(M-|S|-2)$是除去$S$和$i,j$的剩余特征(的个数)
-  $2(M-1)!$包含$i$和$j$的特征子集对于 $\phi_{i,j}$ 的贡献总和即$(M-1)!+(M-1)!$
- $|S|!$代表子集的个数
- 因为子集的个数是特征的个数的指数级别，例如$|S|! = 1 \times 2 \times \cdots \times |S|$
  所以需要使用阶乘进行归一化
	- 整个系数的作用就是将特征子集 $S$ 对于 $\phi_{i,j}$ 的贡献进行了归一化，使得在不同大小的特征子集的情况下，它们对于 $\phi_{i,j}$ 的贡献是可以比较的。
	- 这个系数可以看作是对于特征子集 $S$ 的一个归一化因子

3.  将**所有特征子集的贡献** **进行加权求和**，得到特征 $i$ 和特征 $j$ 的相互作用值 $\phi_{i,j}$。

- 通过上面的举例也可以同样计算其中k个特征的组合贡献
$$
\phi_{i_1,...,i_k} = \sum_{S\subseteq N\{i_1,...,i_k\}}\frac{|S|!(M-|S|-k)!}{k(M-(k-1))!}\delta_{i_1,...,i_k}(S)
$$
通过计算特征相互作用值，可以更好地理解模型中特征之间的交互关系，从而帮助我们更好地解释模型的预测结果。此外，SHAP值还可以用于计算特征的重要性、生成特征依赖图、提供局部解释和汇总图等，进一步提高模型的可解释性。

---
#### Kernel  SHAP
Kernel  SHAP 是一种与模型无关的方法，**可用于估计任何模型的 SHAP 值**。因为它不对模型类型做出假设，所以 KernelExplainer 也会比其他特定于模型类型的算法慢。
- Kernel SHAP 技术是基于 LIME 技术的一种改进版本，用于解释机器学习模型的预测结果。
- 在 Kernel SHAP 中，**使用加权线性回归作为局部代理模型**，并使用一种适当的加权核函数来分配新生成的样本的权重。然后，**使用这个局部代理模型来解释机器学习模型的预测结果**。

在 SHAP 论文中，作者们证明了，在**使用加权线性回归模型和适当的权重核函数**时，局部代理模型的**回归系数可以估计出 SHAP 值**。SHAP 值是一种用于解释机器学习模型的决策的技术，它可以计算每个特征对于模型输出的贡献度。


>参考链接：[9.6 SHAP (SHapley Additive exPlanations) | Interpretable Machine Learning](https://christophm.github.io/interpretable-ml-book/shap.html#kernelshap)

Kernel SHAP 估计（预测模型的某次预测结果x） 实例x 中 每个特征值对预测的贡献。 
Kernel SHAP 由五个步骤组成：
-   联盟样本$z'_k \in \{0,1\},k\in \{1,...,K\}$（1 = 联盟中存在的特征，0 = 不存在特征）。
-   获取每个的预测$z_k'$,通过首先转换$z_k'$到原始特征空间，然后应用模型$\hat{f}:\hat{f}(h_x(z_k'))$
-   计算每个的权重$z_k'$与 Kernel SHAP。
-   拟合加权线性模型。
-   返回Kernel SHAP值$\phi_k$，即线性模型中的系数

---
##### 举例
- 我们可以通过反复抛硬币来创建一个随机联盟，直到我们有一个 0 和 1 的链。 例如，（1，0，1，0） 的向量表示我们有第一个和第三个特征的联盟。 K 采样联盟将成为回归模型的数据集。 回归模型的目标是对联盟的预测。 
- 为了从特征值联盟转换到有效数据实例，我们需要一个函数
$$
h_x(z') = z\ 
使得 h_x:\{0,1\}^M \to R^p
$$

- 函数$h_x$将 1 映射到我们要解释的实例 X 中的对应特征值。
- 对于表格数据，它将 0 映射到我们从数据中采样的另一个实例的值（非此实例X的对应特征值）。 这意味着我们将“*特征值不存在*”等同于“*特征值被数据中的随机特征值替换*”。 对于表格数据，下图可视化了从联盟到特征值的映射：
![](https://christophm.github.io/interpretable-ml-book/images/shap-simplified-features.jpg)


$h_x$对于表格数据处理时，**其中特征$x_j$和$x_{-j}$（其他特征）被视为相互独立**，并在边缘分布上进行积分：
$$
\hat{f(h_x(z'))} = E_{X_{-j}}[\hat f(x)]
$$
从边际分布中抽样意味着忽略当前特征和不存在特征之间的依赖关系结构。

 因此，Kernel SHAP 与所有基于排列的解释方法都存在相同的问题。 该估计对不太可能的情况给予了过多的重视。 结果可能变得不可靠。 
 - 但需要从边际分布中抽样。
原因是从条件分布中采样时，虽然从条件分布中采样可以避免这个问题，但这会改变值函数，从而改变Shapley值作为解决方案的游戏，导致Shapley值的解释方式发生变化。例如，当使用条件抽样时，可能根本没有使用的特征可以具有非零的Shapley值。

例如对于图像，下图描述了可能发生的条件预测时映射函数：
- 对于图像处理，缺少特征也就是 （0）时，$h(x)$的相应区域应该变灰
- 但明显样本中没有办法使sp3为0的情况出现
![](https://christophm.github.io/interpretable-ml-book/images/shap-superpixel.jpg)
---
##### SHAP 与 LIME
**与 LIME 的最大区别在于回归模型中实例的权重。**
- LIME 根据实例与原始实例的接近程度（最小损失函数）对实例进行加权。 联盟向量中的 0 越多，LIM 中的权重越小。
- SHAP 方法中采用的权重是**基于 Shapley 值估计**得到的权重。（ *根据这个特征的丢失或存在对预测结果的造成的影响* 而进行的加权）
	 - 对于一个特征的重要性程度，*与它所在的组合的大小有关*。
	 - 组合中1的数量***越少或越多，该组合对应的特征的重要性就越高***。
	 - 这个性质的直觉解释是，我们***最容易了解一个特征的影响***是在它在其他特征影响下被隔离出来研究，也就是***当一个特征单独存在或者与其他特征的影响完全不同的时候***。
		 - 如果一个组合只有一个特征，那么这个特征的影响就可以被单独考虑；如果一个组合除了某一个特征以外其他特征都有时，那么这个特征的总影响（包括主效应和特征交互）就可以较容易的被研究。
		 - 而如果一个组合中包含了一半的特征，那么对于某个特定的特征，该特定特征对该特征组合的影响与其他许多包含该特征的组合的影响是相同的，因此对于该特征的贡献的了解程度就比较有限。

---
##### Kernel SHAP公式说明
为了实现与Shapley兼容的权重，Lundberg等人提出了Kernel SHAP：
在 Kernel SHAP 中，使用的权重核函数被称为 Shapley 核函数，它可以恢复出 Shapley的值。Shapley 核函数的计算公式如下：
$$
\pi_{x'}(z') = \frac{(M-1)}{{M \choose |z'|}|z'|(M-|z'|)} ,
$$
其中，$M$ 是最大联盟规模（特征组合中特征数量），$|z'|$ 是样本 $z'$ 中特征的数量。这个公式的含义是，对于给定的特征样本(特征子集) $z'$，计算**它对应的 Shapley 值的权重**。
- $\pi_{x'}(z')$ 表示将子集 $z'$ 与其余特征的排列组合进行比较时，子集$z'$所占权重
	- 分母表示了选出 $|z'|$ 个样本的方案数，而分子表示了每个样本被选中的可能性，因此二者的比值可以用来对样本进行加权，从而计算 Shapley 值
	- 分母中的 $|z'|(M-|z'|)$ 表示了一个样本被选中后，还需要选中剩下的 $(M-|z'|)$ 个样本，因此乘上这两个值就可以得到选出 $|z'|$ 个样本的总方案数。而分子中的 $(M-1)$ 则表示在这些方案中，每个样本都被赋予相同的权重，即每个样本都有相同的可能性成为最终选中的样本之一。

因此，Kernel SHAP 可以使用局部代理模型来解释机器学习模型的预测结果，并计算每个特征对于模型预测的贡献度，从而提供对模型决策的解释和洞察构建加权线性回归模型：
$$
g(z') = \phi_0+\sum_{j=1}^M \phi_j z_j'
$$
通过优化以下损失函数 L 来训练线性模型 g：
$$
L(\hat{f},g,\pi_x) = \sum_{z' \in Z}[\hat{f(h_x(z'))-g(z')}]^2 \pi_x(z')
$$

其中 Z 是训练数据。 这是我们通常针对线性模型优化的损失函数平方和。 
模型的估计系数$\phi_j$是shapley值。

---
#### 总结
>来自论文：
- [[Explainable AI_A Review of Machine Learning.pdf|Explainable AI_A Review of Machine Learning]]

在所介绍的方法中，**SHAP是最完整的方法**，它可以在全局和局部范围内为任何模型和任何类型的数据提供解释。**但SHAP并不是没有缺点:** SHAP的核版本，像大多数基于排列的方法一样，KernelSHAP没有**考虑到特征依赖**，因此**往往会给不太可能的数据点分配过高的权重，导致解释结果不准确**，而SHAP的树版本**TreeSHAP**则解决了这个问题，因为它**考虑了特征之间的依赖关系**。但由于TreeSHAP依赖于条件预测值，因此可能会**导致一些没有对预测结果产生影响的特征被分配一个非零的重要性值**，这可能会导致解释结果不直观。

KernelSHAP 通常用于解释时间序列预测，但它在该领域确实存在一些重大限制和缺点：
[SHAP for Time Series Event Detection | by Nakul Upadhya | Feb, 2023 | Towards Data Science](https://medium.com/towards-data-science/shap-for-time-series-event-detection-5b4d9d0f96f4)
- 可能会导致在应用 KernelSHAP 时出现计算数值下溢错误，尤其是在多变量时间序列预测
-  KernelSHAP 假定特征独立。这通常适用于表格数据情况，但特征和时间步长的独立性是一个例外，而不是时间序列中的常态。
-  KernelSHAP 使用已被用于拟合数据扰动（perturbations）的线性模型系数。
	然而，在时间序列情况下，[向量自回归模型](https://online.stat.psu.edu/stat510/lesson/11/11.2)（VAR）通常更倾向于对过程进行建模，而不仅仅是线性模型[3]。
![[Pasted image 20230402123623.png]]
摩根大通人工智能研究部门的研究人员（Villani 等人）在 [2022 年 3 月的论文](https://arxiv.org/abs/2210.02176)提出了更适合时间序列数据的 KernelSHAP 变体

---
## Morris(Sensitivity Analysis)

#### SA (Sensitivity Analysis)
**什么是灵敏度分析?**
- **研究输入因素的变化是如何影响数值模型输出的过程**

**举例**
- 假设 Sue 是一名销售经理，他想要了解客户流量对总销售额的影响。她确定销售额是价格和交易量的函数。一个小部件的价格是1美元，Sue去年卖出了000个，总销售额为100万美元。

- Sue 还确定，客户流量每增加 10%，交易量就会增加 5%。这使她能够基于假设语句围绕这个等式建立[财务模型](https://www.investopedia.com/terms/f/financialmodeling.asp)和敏感性分析。它可以告诉她，如果客户流量增加 10%、50% 或 100%，销售额会发生什么。

- 根据今天的 100 笔交易，客户流量增加 10%、50% 或 100% 分别相当于交易增加 5%、25% 或 50%。敏感度分析表明，销售对客户流量的变化高度敏感。

**灵敏度分析的可用场景**
敏感性分析的用途范围包括但不限于：
-   **了解影响因素。** 这包括不同的外部因素与特定项目或事业相互作用的内容和方式。这使管理层能够更好地了解哪些输入变量可能会影响输出变量。
-   **减少不确定性。** 复杂的敏感性分析模型向用户介绍影响项目的不同元素;这反过来又告知项目成员需要警惕什么或提前计划什么。
-   **捕获错误。** 基线分析的原始假设可能存在一些未发现的错误。通过执行不同的分析迭代，管理层可能会发现原始分析中的错误。
-   **简化模型。** 过于复杂的模型可能会使分析输入变得困难。通过执行敏感性分析，用户可以更好地了解哪些因素实际上并不重要，并且由于缺乏重要性，可以从模型中删除。
-   **传达结果。** 高层管理人员可能已经对一项事业具有防御性或好奇性。汇编对不同情况的分析有助于让决策者了解他们可能有兴趣了解的其他结果。
-   **实现目标。** 管理层可以制定必须符合特定基准的长期战略计划。通过执行敏感性分析，公司可以更好地了解项目可能如何变化，以及团队必须具备哪些条件才能实现其指标目标

**灵敏度分析与情景分析**
- 情景分析是基于事实和经验判断的，灵敏度分析是不考虑实际不考虑经验进行理论预计，可能出现不切实际的情况

 **灵敏度分析的利与弊**
**优点**
-   根据风险或不断变化的变量提供不同的输出情况
-   可以帮助管理层针对具体投入实现更具体的结果
-   可以轻松沟通需要关注的领域或需要控制的最大风险
-   可以*识别原始基准中的错误*
-   通常*减少给定任务的不确定性和不可预测性*
**缺点**
-   可能严重依赖将来可能不会实现的假设
-   可能会给计算机系统带来复杂、密集的模型负担
-   可能会变得过于复杂，从而扭曲分析师的能力
-   可能无法准确积分自变量（因为一个变量可能无法准确积分另一个变量的影响）

---
#### Morris
	Paleari L, Movedi E, Zoli M, et al. Sensitivity analysis using Morris: Just screening or an effective ranking method?[J]. Ecological Modelling, 2021, 455: 109648.

该方程计算了在保持所有其他参数不变的情况下，**当第i个参数的值发生变化时，模型输出值将如何变化**
$$
R_i(X,\Delta) =\frac {y(x_1,...,x_{i-1},x_i+\Delta,x_{i+1},...,x_N)-y(X)}{\Delta}
$$

- $X = (x_1, …, x_N)$ : 表示由模型参数组成的向量。它包含N个元素，每个元素$x_i$代表第i个参数的初始值。
- $p$: 每个参数$x_i$将从$\{0,{1\over{p-1}},{2\over{p-1}},...,{p-2\over{p-1}},1\}$中取值，也就是说**每个参数可以取p个不同的值,最小是0，最大是1**。
- $Δ =\frac{1}{(p-1)}$: 这是从上面取值集合中推导所得的，表示第i个参数$x_i$的**每次的变化值**。
- $y(X)$代表模型的**原始输出值**（没有$\Delta$变化时）
- $y(x1，…，xi-1, xi+Δ， xi+1，…，xN):$这表示在保持所有其他参数不变的情况下，当第i个参数变化Δ时模型的输出。
- $Ri(X, Δ)$:表示第i个参数变化时输出值的影响，称之为**初等效应**。它的计算方法是，当第i个参数发生变化时，原始参数值设定时的模型的输出 与第i个参数变化后的输出值之差 除以 Δ（第i个参数的变化量）。

Morris 方法使用以上公式为基础，**识别模型中哪些参数对输出结果影响最大**。
- 其中，Morris方法采用Ω 超空间的概念，简单来说Ω表示**各参数取值范围的集合**。
- 在 Morris 方法中：
	- 首先从上述**各参数取值范围的集合**中随机抽样，用于表示参数空间中的一个点。
	- 接着，变化其中一个参数其余参数保持不变，计算模型输出。
	- 重复上一步，然后更改另一个参数，对模型进行评估。
	- 在每个点上，仅有一个参数被微小地改变（Δ），其他参数保持不变。
	- 一直到所有参数都进行过变化，从而产生一条轨迹。
	- （参考论文：Andersson M, Streb M, Ko J Y, et al. Parametrization of physics-based battery models from input–output data: a review of methodology and current research[J]. Journal of Power Sources, 2022, 521: 230859.）
- 假设采样共形成 r 条轨迹（**进行r次采样**），每个轨迹由 N+1 个点组成。
	- (每个轨迹有一个随机生成的不同初始参数值组成的点，剩下N个分别代表每个参数值进行一次变化，所以是N+1次)
- 相比传统的**逐一变动参数进行敏感度分析方法**，Morris 方法通过在 Ω 超空间中沿着轨迹变动参数（一次变动多个参数，得到r个值）的方式来评估模型，可以更高效地进行敏感度分析。此外，Morris 方法在变动参数时避免了参数重复取值的情况，可以帮助减少敏感度分析中的偏差。
	- 传统的敏感度分析方法通常采用一次只变动一个参数的方式，但是这种方法容易出现误差，因为它没有考虑*不同参数之间的相互作用和非线性效应*。
	- 而Morris方法采用了*多参数同时变动的方式，就可以更全面地考虑参数之间的相互作用和非线性效应。*

- 接着,由于各参数被定义在单位超空间中，即每个参数的取值范围都是$[0,1]$（如上公式），在完成Morris采样后，得到的是每个参数的敏感度指标$R(x_i,\Delta)$，根据指定的参数分布范围从单位超空间缩放回参数原始范围。
- 因此对于每个 $R_i$ 分布，计算其平均值（μ）和标准差（σ），这代表每个参数$x_i$的敏感度度量。平均值（μ）量化了参数对模型输出的总体影响（总敏感度效应），而标准差（σ）则识别了具有非线性影响或参与其他参数交互作用的参数。
	- 标准差通常用于反应数据的离散程度。如果某个参数对模型输出的影响非常不稳定，那么在不同的取值范围会导致模型输出值差异很大，从而导致它$R_i$分布计算出的标准差就会很大。
	- 因此，**标准差越大**，说明参数对模型输出的敏感度越强，也就是，**参数的取值对模型的影响非常明显**，**这个参数对于模型的结果非常关键**。
另外本文中的μ通过对$|R_i|$而不是$R_i$进行平均值计算得出。

---
#### 总结

- 在SA方法通常按照“**简约性**“进行分类，简约性从高到低被分为**筛选**和**基于方差**的方法，其中morris和E-FAST是最流行的方法。
- Morris通常用于在计算量很大的模拟实验中筛选无影响的参数，被认为是最有效的筛选方法之一。
- E-FAST的计算成本低于其他基于产出方差分解的方法。

在对方法进行评估的时候，方法表现并不稳定：
为对SA方法进行评估与排名，人们对基于方差的方法和morris方法进行了实验评估。但不同的研究结果并不明显相同，有的对该方法morris评估较好，但有的研究也认为morris方法评估表现较差，这
- 可能是由于不同学科或是SA对不现实的假设的依赖性，大部分研究倾向于是因为当输入变量分布不均匀，或morris低估了某些输入变量与输出变量的之间相关性，尤其当输入和输出变量之间存在较强的非线性时（容易被低估)，导致Morris和基于方差的结果之间存在分歧。
在论文 [Sensitivity analysis using Morris: Just screening or an effective ranking method?](https://www.sciencedirect.com/science/article/pii/S0304380021002088)中，两种方法得到的参数排名的一致性（TDCC）总是在显著性水平0.05下，且所得到的敏感度估计值之间无线性关系。