**Table of Contents**

-  [[#来自Forecasting gold price with the XGBoost algorithm and SHAP interaction values的研究背景与研究原因|来自Forecasting gold price with the XGBoost algorithm and SHAP interaction values的研究背景与研究原因]]
-  [[#SHAP (SHapley Additive exPlanation) approach for results interpretation|SHAP (SHapley Additive exPlanation) approach for results interpretation]]
-  [[#举例说明|举例说明]]
-  [[#Shapley|Shapley]]
-  [[#TreeSHAP|TreeSHAP]]
-  [[#Shapley Kernel|Shapley Kernel]]

---
## 小总结

阅读文章：
- Jabeur S B, Mefteh-Wali S, Viviani J L. Forecasting gold price with the XGBoost algorithm and SHAP interaction values[J]. Annals of Operations Research, 2021: 1-21.
- Lundberg, S. M., Erion, G. G., & Lee, S. -I. (2018). Consistent Individualized Feature Attribution for Tree Ensembles. 2.
- Lundberg S M, Lee S I. A unified approach to interpreting model predictions[J]. Advances in neural information processing systems, 2017, 30.

1. 从shapley ,TreeSHAP到Kernel SHAP的逐步理解，<u>Kernel SHAP</u>的理解还在进行中，还不敢说自己完全理解了。
2. 另外SHAP的理解和昨天morris一样，多来源于<u>论文</u>中，中间有部分举例取自知乎（简单用例子更通俗易懂的理解shapley)
3. 还有不足的地方是：
- 对上述算法的使用论文阅读还较少，从论文中应该能对<u>XAI算法的选择原因</u>进行总结；
- 对上述算法的优缺点缺乏总结；
- 数学公式的理解较为模糊，靠直觉的理解偏多，缺乏<u>每一步详尽的使用理解</u>

最后查到两个kernel shap的链接，便于准备明天的kernel shap理解：
- [SHAP Part 2: Kernel SHAP. Kernel SHAP is a model agnostic method… | by Rakesh Sukumar | Analytics Vidhya | Medium](https://medium.com/analytics-vidhya/shap-part-2-kernel-shap-3c11e7a971b1)
- [KernelSHAP vs TreeSHAP. Comparing SHAP approximation methods… | by Conor O'Sullivan | Towards Data Science](https://medium.com/towards-data-science/kernelshap-vs-treeshap-e00f3b3a27db)

---
#### 来自Forecasting gold price with the XGBoost algorithm and SHAP interaction values的研究背景与研究原因
	-  Jabeur S B, Mefteh-Wali S, Viviani J L. Forecasting gold price with the XGBoost algorithm and SHAP interaction values[J]. Annals of Operations Research, 2021: 1-21.

Then it is the frst, to the best of our knowledge, to analyze the importance of individual features of gold price fuctuation using SHAP (SHapley Additive exPlanation). Gold price has signifcant nonlinear, time-varying, many infuence factors in consequence it is especially important to detect the most infuential factors frst and then to combine them in order to improve prediction accuracy.

考虑到黄金价格具有显著的非线性、时变、多因素的影响，因此，作者首先找出影响最大的因素，然后将其组合起来以提高预测精度。文中作者使用SHAP (SHapley加法解释)，分析黄金价格波动的个别特征的重要性。

选择SHAP方法的原因：
- 据我们所知，SHAP交互值尚未应用于**分析财务数据集**，这是第一次:

		> Second, in terms of model interpretation—which is especially important when using machine learning models that are often difcult to interpret—several studies have started to take advantage of SHAP (Ribeiro et al., 2016; Štrumbelj and Kononenko, 2014). We have applied SHAP for the frst time. To the best of our knowledge, SHAP interaction values have not yet been applied to analyze fnancial data set.

- 在实际的财务决策情况中，决策者不仅需要做出准确的预测，他们还必须证明预测是如何获得的，以及为什么做出给定的决定(例如，基于借款人的财务状况拒绝贷款;或者购买/出售金融资产，在我们的例子中是黄金)。在学术界，理解变量之间的因果关系和原因的层次也很重要。
- 将预测推高的特征与将预测推低的特征是不同的。SHAP值可以帮助我们理解每个特征对于模型输出的影响，特别是在多个特征同时影响模型输出的情况下。这种方法可以帮助我们更好地解释模型预测结果，并揭示不同特征之间的相互作用和影响。

		> In practical fnancial decision situations, decision makers not only need to make accu‑rate predictions, they also have to justify how predictions are obtained and why a given decision is taken (for instance to refuse a loan based on the fnancial status of the borrower; or to buy/sell a fnancial asset, in our example gold). In the academic world, it isalso important to understand the causal relationships between variables and the hierarchy of causes. To answer these practical and theoretical concerns, we use SHAP to explain the output of the machine learning model. The idea of SHAP is to show the contribution of each feature to run the model output from the base value of explanatory variables to the model output value. In short, SHAP values represent a feature’s responsibility for a change in the model output. Features pushing the prediction higher are distinguished from those pushing the prediction lower. To our knowledge, SHAP interaction values have not yet been applied to analyze fnancial data set.

---
#### SHAP (SHapley Additive exPlanation) approach for results interpretation
- 机器学习在预测时间序列数据方面具有巨大的潜力。但研究人员通常不会解释他们的预测，这是采用机器学习的障碍。
- 为了克服这个问题，Lundberg和Lee(2017)提出了一种SHAP方法来解释不同技术的预测，包括LightGBM、NGBoost、CatBoost、XGBoost和Scikit-learn树模型。
- SHAP帮助用户解释复杂模型的预测。Shapley最初于1953年提出，它基于博弈论(Shapley, 1953)。它允许我们通过计算每个特征对预测的影响来解释特定输入(X)的预测。Shapley估计值的计算方法如下:
$$
\hat{\phi}_j = {{1}\over{K}}\sum_{k=1}^{K}{( \hat{g}\left(x_{+j}^{m}\right)-\hat{g}\left(x_{-j}^m\right))}
$$

Shapley值是一种用于**衡量特征对于模型预测的贡献程度**的方法。
Shapley值的核心思想是：
- 对于一个特征，它对于模型预测的贡献程度指 ：
	在所有可能的特征子集中，它被添加到这些子集中后，所造成的模型预测变化值的平均值。

---
#### 举例说明
假设以下情形：已经训练了一个机器学习模型来预测公寓价格，分别有park、size、floor、car四个特征。某个面积为50平方米（size=50）、位于二楼（floor=2nd）、附近有一个公园（park=nearby）、禁止猫咪（cat=banned）的公寓，它预测价格为300,000欧元，你需要解释这个预测，即每个特征是如何促进预测的？当所有公寓的平均预测为310,000欧元时，与平均预测相比，每个特征值对预测的贡献是多少？

假设park=nearby，cat=banned，size=50，floor=2nd的特征值共同实现了300,000欧元的预测。我们的目标是解释实际预测（300,000欧元）和平均预测（310,000欧元）之间的差异：-10,000欧元。
答案可能是：park=nearby贡献了30,000欧元，size=50贡献了10,000欧元，floor=2nd贡献了0欧元，cat=banned贡献了-50,000欧元，这些贡献加起来为-10,000欧元，即最终预测减去平均预测的公寓价格。

**那实际上我们应该如何计算目标公寓实例（park=nearby，cat=banned，size=50，floor=2nd）其中一个特征的Shapley值？**

**Shapley值是所有可能子集集合中特征值的平均边际贡献**。
以该公寓实例的cat=banned为例，在下图中，我们估计了cat=banned特征值被添加到park=nearby和size=50的联盟后的贡献。
- 第一步，我们从数据中随机抽取另一个公寓（*该公寓floor=1st，cat=allowed，park和size可以不关注*），
- 使用该公寓自己的floor特征值1st，模拟出park=nearby，size=50和cat=banned的联盟，这个组合（*floor=1st，park=nearby，size=50和cat=banned*）预测公寓的价格刚好为310,000欧元。
- 第二步，我们从联盟中删除*cat=banned*，然后用该公寓的cat特征值allowed替代，我们用这个组合（*floor=1st，park=nearby，size=50和cat=allowed*）预测公寓的价格为320,000欧元。

![](https://pic1.zhimg.com/80/v2-13f5f6c41152bba5fa5ed8728e43f62c_720w.webp)
            (假设我们改变其中一个特征后，理论目标值就变为平均值)

- 可以看到，基于我们随机抽取的公寓，我们预测park=nearby，size=50和cat=banned的联盟的公寓价格为310,000欧元，预测park=nearby和size=50的联盟的公寓价格为320,000欧元，那cat=banned的贡献是310,000欧元 - 320,000欧元 = -10,000欧元。
- 由于该公寓充当cat和floor特征值的“供体（donor）”，所以*这个估计值取决于随机抽取的公寓的值*，如果我们**重复这个抽样步骤并取贡献的平均，我们将得到更好的特征贡献值估计**。

上面只介绍了park=nearby和size=50集合的贡献，而Shapley值是所有可能联盟的所有边际贡献的平均值，所以我们应该对所有可能的联盟重复这个计算。计算时间随着特征的数量和每个联盟中抽样的实例数量呈指数增长。下面是计算目标公寓的**cat=banned**的Shapley值的所有特征值（除cat外其他特征所构成的子集）集合：

-   空集合
-   park=nearby
-   size=50
-   floor=2nd
-   park=nearby 和 size=50
-   park=nearby 和 floor=2nd
-   size=50 和floor=2nd
-   park=nearby 和size=50 和floor=2nd.

对于这些联盟中的每一个，我们**计算带有和不带有cat=banned特征值的预测公寓价格，并计算差值来获得边际贡献，Shapley值是边际贡献的（加权）平均值**，我们用来自数据集的随机公寓的特征值替换不在联盟中的特征的特征值，以从机器学习模型获得预测。如果我们估计所有特征值的Shapley值，我们将得到特征值中预测的完整分布（减去平均值）。

具体来说，Shapley值的计算方法是通过**计算所有可能特征子集对于模型预测的影响**来进行的。
- 在这个计算过程中，**每个特征子集被视为一个“玩家联盟”，每个特征被视为一个“玩家”，而每个特征在一个特征子集中的出现被视为一个“合作行为”。**

---
#### Shapley
计算Shapley值的过程中，首先需要确定每个特征子集的“贡献”，即该特征子集中每个特征的贡献值。然后，通过将每个特征子集的“贡献”加权平均，就可以得到每个特征的Shapley值。
$$
\hat{\phi}_j = {{1}\over{K}}\sum_{k=1}^{K}{( \hat{g}\left(x_{+j}^{m}\right)-\hat{g}\left(x_{-j}^m\right))}
$$
上述公式中，
- $\hat{\phi}_j$ 表示特征 $j$ 的Shapley值的估计值，
- $\hat{g}\left(x_{+j}^{m}\right)$ 表示将特征 $j$ 的值设置为 $x_{+j}^{m}$ 时模型的预测值，
- $\hat{g}\left(x_{-j}^m\right)$ 表示将特征 $j$ 的值从原始的输入 $x$ 中删除后，模型的预测值。
- $K$ 表示采样的次数。

具体地，计算 $\hat{\phi}_j$ 的过程中，
- 对于每一次采样 $k$，
- 需要从输入 $x$ 中**随机选择一些特征**，并将这些特征的值设置为 $x_{+j}^{m}$
	- $x_{+j}^{m}$ 表示将样本 $m$ 中除了第 $j$ 个特征以外的所有特征值保持不变，而将第 $j$ 个特征的值设置为**训练集中特征j的随机值** ，从而得到的新样本。
- 然后将特征 $j$ 的值设置为原始输入 $x$ 中的值。
- 得到一个新的输入 $\tilde{x}_k$。
- 然后，计算模型在输入 $\tilde{x}_k$ 上的预测值 $\hat{g}(\tilde{x}_k)$，预测新样本k的模型预测值

- 接着，需要对所有采样得到的预测值进行平均，并减去**特征 $j$ 不出现时的平均预测值**，从而得到 $\hat{\phi}_j$ 的估计值。
	
	这样可以将第 $j$ 个特征在样本 $m$ 中的影响单独拎出来，从而更好地衡量该特征对于模型预测的贡献。

---
#### TreeSHAP
在Lundberg等人(2018)的工作中，TreeSHAP是一种计算**决策树模型**中**特征相互作用值**的方法。特征相互作用值指的是**两个特征在一起出现时对于模型预测的贡献程度**。
   - (组合特征对于特征预测的贡献程度)

具体来说，根据Lundberg等人(2018)的方法，特征 $i$ 和特征 $j$ 的相互作用值可以通过对所有**包含特征 $i$ 和特征 $j$ 的特征子集**进行**加权求和**来进行估计。其中，每个特征子集被视为一个“玩家联盟”，每个特征被视为一个“玩家”，而每个特征在一个特征子集中的出现被视为一个“合作行为”。

	- Lundberg, S. M., Erion, G. G., & Lee, S. -I. (2018). Consistent Individualized Feature Attribution for Tree Ensembles. 2.

具体地，根据Lundberg等人(2018)的公式，特征 $i$ 和特征 $j$ 的相互作用值 $\phi_{i,j}$ 可以通过以下方式进行计算：
1.  
  - 对于**所有特征子集** $S\subseteq N\{i,j\}$
  计算 $\delta_{i,j}(S)$ 
   - $\delta_{i,j}(S)$代表有{i,j}时的预测值和无特征值{i,j}进行模型预测的差：
$$
\delta_{ij}(S) = f_x(S ∪ \{i, j\}) − f_x(S ∪ \{i\} )− f_x(S ∪ \{j\}) + f_x(S)
$$
其中  $(i≠j)$，$f_x(S)$ 表示模型在**特征子集 $S$ 上的预测值**

- $f_x(S)$ 表示只考虑特征子集 $S$ 时得到的模型输出值，
- $f_x(S ∪ {i})$、$f_x(S ∪ {j})$ 和 $f_x(S ∪ {i, j})$ 则表示加上特征 $i$、加上特征 $j$ 和加上特征 $i$ 和 $j$ 后得到的新样本的模型输出值。

因此，$f_x(S \cup {i})$ 的意义是包含特征 $i$ 和 $S$ 中其它特征的子集对应的模型预测值。这个值与 $\delta_{ij}(S)$ 中的其它三个值一样，都是为了计算特征 $i$ 和特征 $j$ 的交互作用值而引入的。
2.  对于**每个特征子集 $S$**，计算**该特征子集**对于**相互作用值**的贡献：
$$
\phi_{i,j} = \sum_{S\subseteq N\{i,j\}}\frac{|S|!(M-|S|-2)!}{2(M-1)!}\delta_{i,j}(S)
$$
其中，$M$ 表示**特征的总数**，$|S|$ 表示**特征子集 $S$ 中包含的特征数**。
- $(M-|S|-2)$是除去$S$和$i,j$的剩余特征(的个数)
-  $2(M-1)!$包含$i$和$j$的特征子集对于 $\phi_{i,j}$ 的贡献总和即$(M-1)!+(M-1)!$
- $|S|!$代表子集的个数
- 因为子集的个数是特征的个数的指数级别，例如$|S|! = 1 \times 2 \times \cdots \times |S|$
  所以需要使用阶乘进行归一化
	- 整个系数的作用就是将特征子集 $S$ 对于 $\phi_{i,j}$ 的贡献进行了归一化，使得在不同大小的特征子集的情况下，它们对于 $\phi_{i,j}$ 的贡献是可以比较的。
	- 这个系数可以看作是对于特征子集 $S$ 的一个归一化因子

3.  将**所有特征子集的贡献** **进行加权求和**，得到特征 $i$ 和特征 $j$ 的相互作用值 $\phi_{i,j}$。

- 通过上面的举例也可以同样计算其中k个特征的组合贡献
$$
\phi_{i_1,...,i_k} = \sum_{S\subseteq N\{i_1,...,i_k\}}\frac{|S|!(M-|S|-k)!}{k(M-(k-1))!}\delta_{i_1,...,i_k}(S)
$$
通过计算特征相互作用值，可以更好地理解模型中特征之间的交互关系，从而帮助我们更好地解释模型的预测结果。此外，SHAP值还可以用于计算特征的重要性、生成特征依赖图、提供局部解释和汇总图等，进一步提高模型的可解释性。

----
#### Shapley Kernel
	- Lundberg S M, Lee S I. A unified approach to interpreting model predictions[J]. Advances in neural information processing systems, 2017, 30.

Kernel  SHAP 是一种与模型无关的方法，**用于估计任何模型的 SHAP 值**。因为它不对模型类型做出假设，所以 KernelExplainer 比其他特定于模型类型的算法慢。