### 使用月度宏观变量作为解释变量：
1. **将数据转换成模型所需的数据表格的形式：**
（1）从eps中选取出满足条件（具有49个连续季度的财报数据）的公司：
```python
df = df.dropna()
# 按照公司代码（TICKER）分组
grouped = df.groupby('TICKER')
# 计算每个公司季度的差分
df['quarter_diff'] = grouped['quarter'].diff()
# 按照公司代码和差分列进行分组
grouped_diff = df.groupby(['TICKER', 'quarter_diff'])
# 计算每个组的计数值
counts = grouped_diff.size().reset_index(name='count')
# 选择计数值等于49的公司代码
ticker_49 = counts[counts['count'] == 49]['TICKER']
# 从原始数据框中选择具有连续49个季度的公司数据
df_49 = df[df['TICKER'].isin(ticker_49)]
# 删去不需要的列
df_49 = df_49.drop(columns = 'quarter_diff') 
```
![[1678466442171.png]]
(2)将8到13的月度宏观经济变量取（1到6）期滞后：
此处选取滞后1到6期是考虑到，从常识上判断**或许目标季度的财报数据会和过去半年的宏观环境更为相关**：==这里也许可以尝试从文献中找证据，或是我们通过特征提取为此提供证据==
```python
data_test = data.groupby(code_var)
def lag(start,end,var):
    length = list(range(start,end+1,1))
    res = []
    for group_name,group_df in data_test:
        group_df.reset_index(inplace=True)
        for lag in length:
            col_name = var + "_lag" + str(lag)
            group_df[col_name] = group_df[var].shift(lag)
        res.append(group_df)
    res = pd.concat(res)
    res = res.dropna()
    res = res.drop_duplicates(['TICKER','ACTUAL'])# 按此两列去重
    return res

data_test = lag(1,7,var)
```
![[1678466570733.png]]

2. **绘制PACF图**
主观的判断合适的滞后期有点不太专业，这里使用下面链接中的PACF系数尝试选择合适的滞后期数：
参考链接：方翔建议的[理解时间序列的ACF与PACF](https://blog.csdn.net/SunJW_2017/article/details/126993853)
- 在AR模型中，判断滞后阶数的选择即是在判断*需要几个时间步可以预测当前值* ,但ACF(自相关系数)用于判断$x_{t-1}$对$x_t$的影响，仅观察$x_{t-k}$对${x_{t-k+1}}$的影响...到$x_{t-1}$对${x_t}$的影响，无法直接确定从$x_{t-k}$对$x_t$的影响。
- 因此引入PACF（偏自相关函数）的概念和使用：
	PACF，指偏自相关函数（Partial Autocorrelation Function），一种计算$x_t$和$x_{t-k}$的相关系数时可移除$x_{t-1}$到${x_{t-(k-1)}}$影响的方法。

```python
df_test = data.groupby(code_var)
import matplotlib.pyplot as plt
from statsmodels.graphics.tsaplots import plot_pacf
for code,group_df in df_test:
    df_acf = group_df[['ACTUAL',var]]
    plot_pacf(df_acf[var], lags=10, auto_ylims=True,method = 'ywm')
    break
```
	默认的方法将产生超出[-1,1]区间的偏自相关系数（PACF）值。在0.13版本之后，statsmodels将更改默认方法为未调整的Yule-Walker方法（'ywm'），因此使用'ywm'方法来避免此问题。
- 但大部分得出的都是下面这个图像，可能是1阶滞后截尾，模型设定约类似AR(1);
结果理解是参考链接[ARIMA（p,d,q）模型原理及其实现 --------python\_arima python](https://blog.csdn.net/weixin_49583390/article/details/121914303?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522167845790616800197093649%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=167845790616800197093649&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-121914303-null-null.142^v73^control_1,201^v4^add_ask,239^v2^insert_chatgpt&utm_term=ARIMA&spm=1018.2226.3001.4187)
![](data:image/png;base64,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)

3. **特征萃取** 
- **Auto Encoder**

   自编码器(Auto Encoder)可以认为是**只有一层隐含层的神经网络，通过压缩和还原实现对特征的重构**。
   - **输入数据是特征，输入层到隐含层是编码器，能将输入压缩成潜在空间表征；隐含层到输出层是解码器，重构来自潜在空间表征的输入**。

还有一些可能的建议：
- 基于信息论的方法：如互信息、信息增益、卡方检验等。
- 基于频率的方法：如词频、TF-IDF等。
- 基于深度学习的方法：如卷积神经网络（CNN）、循环神经网络（RNN）等。

[(使用DNN训练神经网络模型时，如何知道每个特征的重要性（像xgboost模型能计算出特征重要性一样）？ - 知乎](https://www.zhihu.com/question/310837513)链接中给出建议
- 1 训练好模型之后，用Out of Bag（或称Test）数据进行特征重要性的量化计算。（可行，但要自己琢磨过程代码，有点费时，可做备用选择）
- 2 定义shapley值，具体计算如下：（有点复杂，但有开源的代码库）

> Shapley值是
1.  相对而言，理论基础非常扎实的一种特征重要性的估值，
2.  但是计算复杂度是指数，所以有很多的近似算法。
3.  有几个性质，其中在这里跟我们实际有关的有俩：
4.  线性：如果你计算了某一个函数的Shapley值，而这个函数在后面又进行了线性变换生成了新的函数，那么你只需要将得到的Shapley值进行相同的线性变换，即可获得新函数的Shapley值
[ICLR 2021｜自解释神经网络—Shapley Explanation Networks - 知乎](https://zhuanlan.zhihu.com/p/345265507)
![[1678467577991.png]]

4. **模型建立**
尝试参考此链接建立LSTM模型：[多变量时间序列的多步预测——LSTM模型](https://zhuanlan.zhihu.com/p/191211602)

---
明天的安排：
1. 检查是否完成了所有所需月度变量的准备（之前CRSP有些数据量很多，分多批次处理，不记得是否完成处理了）
2. 同时，尝试使用滞后1至6期的LSTM拟合宏观数据进行预测（之前的工作中深度学习多出现过拟合现象，根据方翔的建议改用LSTM，似乎是更适合时间序列的预测的，另外深度学习的拟合对训练数据量+训练时间要求都比较高，不断拟合的过程中需要学习别人是怎么处理的）