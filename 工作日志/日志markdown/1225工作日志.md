- 结合论文《Machine Learning Time Series Regressions With an Application to Nowcasting》中**第二部分High-Dimensional Mixed-Frequency Regressions** 理解midasml 包参数
>可能是对文章整体思路缺乏理解，需要整体理解来找切入点，理解各个函数使用过程

- 在阅读过程中将数据代入函数中帮助理解

### cv.sglfit
同`cv.panel.sglfit`
对sg-LASSO回归模型进行k-fold交叉验证,返回==lam.min和lam.1se==。计算固定的$\gamma$

用法：

	cv.sglfit(x, y, lambda = NULL, gamma = 1.0, gindex = 1:p, nfolds = 10, foldid, parallel = FALSE, ...)

```R
set.seed(1)
x = matrix(rnorm(100 * 20), 100, 20) # 2000 = 100*20
beta = c(5,4,3,2,1,rep(0, times = 15)) 
y = x%*%beta + rnorm(100) # 100
gindex = sort(rep(1:4,times=5)) 

cv.sglfit(x = x, y = y, gindex = gindex, gamma = 0.5, standardize = FALSE, intercept = FALSE)
```


```R
# 例
xx_vector <- nx[1:1008]
xx <- matrix(xx, nrow = 12, ncol = 84, byrow = TRUE)
yy <- ny[1:12]
gindex = sort(rep(1:28,times=3)) 
cv.sglfit(x = xx, y = yy, gindex = gindex, gamma = 1,standardize = FALSE, intercept = FALSE)
```

- gindex : P乘1向量表示每个协变量的组成员关系

----

### midas.ardl 
进行midas回归

拟合单高频协变量MIDAS回归模型(ARDL-MIDAS模型)。选项包括线性参数多项式(例如Legendre多项式)或非线性多项式(例如指数Almon多项式)。
使用单个协变量拟合MIDAS。可选择线性参数多项式如Legendre或非线性多项式（如指数阿尔蒙）。非线性多项式的优化路线通过分析梯度建立，可实现快速且精准的优化。

	midas.ardl(y, x, z = NULL, loss_choice = c("mse","logit"),  
	poly_choice = c("legendre","expalmon","beta"),  
	poly_spec = 0, legendre_degree = 3, nbtrials = 500)

- y是响应变量。连续的变量选择损失函数loss_choice = "mse",由两部分组成的变量损失函数选择loss_choice = "logit"

- x是高频协同滞后变量

- z是其他低频的协同变量 或 AR滞后（都可以在附加矩阵中提供）两者都必须被提供。

- loss_choice 是拟合的损失函数 。 当loss_choice=mse拟合更少的符合要求的midas回归，loss_choice=logit拟合多元的midas回归
- poly_choice 是使用的midas滞后多项式函数。可选择expalmon\beta\legendre几个函数。默认使用expalmon。
- legendre_degree（仅适用于legendre="beta"） legendre多项式的次数，默认3次
- nbtrials 在多次初始优化中尝试的初始值的数目。默认设置为poly_spec= 500.


---
### tscv.sglfit
时间序列k-fold交叉验证拟合sg-LASSO
参数理解同cv.sglfit
```R
set.seed(1)  
x = matrix(rnorm(100 * 20), 100, 20)  
beta = c(5,4,3,2,1,rep(0, times = 15))  
y = x%*%beta + rnorm(100)  
gindex = sort(rep(1:4,times=5))  
tscv.sglfit(x = x, y = y, gindex = gindex, gamma = 0.5,  
standardize = FALSE, intercept = FALSE)
```

---
