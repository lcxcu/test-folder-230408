1. 变量6（第m个月的特定公司股票收益-第m个月的同行业投资组合收益）的汇整：
![[Pasted image 20230312232918.png]]
---
2. LSTM模型预测:
- 中间有一版本的模型预测误差没这么大，应该是参数设定没问题，但忘记保存图了，那一版本结果有较大滞后。（当时平均预测错误率为0
- 这一版本的模型设定则有问题，平均错误率很高
![[Pasted image 20230312232813.png]]
下面的代码参数设定有问题，鑫绘的论文里也提到LSTM虽然擅长时间序列预测，但在高频数据中预测不佳，明天还是改用**神经网络**：[ pytorch深度学习：神经网络拟合方程(回归问题)\_神经网络拟合函数pytorch\_BUAA小乔的博客-CSDN博客](https://blog.csdn.net/qq_37333048/article/details/110469670)
```python
# 2. 定义准备数据的函数
def prepare_data(dataset, n_i=1, n_out=1, n_vars=6, train_proportion=0.8):
    # 训练集比例0.8
    #读取数据集
    #dataset = dataset
    #设置时间戳索引
    dataset['datadate'] = pd.to_datetime(dataset['datadate'])
    dataset.set_index("datadate", inplace=True)
    values = dataset.iloc[:,1:].values
    #保证变量数据都是float32类型
    values = values.astype('float32')
    #变量归一化
    scaler = MinMaxScaler(feature_range=(0, 1))
    scaled = scaler.fit_transform(values)
    n_train = round(dataset.shape[0]*train_proportion)
    train = values[:n_train, :]
    test = values[n_train:, :]
    #分隔输入X和输出y
    #从第三列（2）到末尾是x, 第一列（0）为y
    train_X, train_y = train[:, 1:], train[:,1]
    # 这里要根据y和x的位置修改,但一般是不用的
    test_X, test_y = test[:, 1:], test[:, 1] # 这里要根据y和x的位置修改,但一般是不用的
    #将输入X改造为LSTM的输入格式，即[samples,timesteps,features]
    train_X = train_X.reshape((train_X.shape[0], n_i, n_vars))
    test_X = test_X.reshape((test_X.shape[0], n_i, n_vars))
#     train_y = train_y.reshape(-1,1)
#     test_y = test_y.reshape(-1,1)
    return scaler, dataset, train_X, train_y, test_X, test_y, dataset
```

```python
# 3. 定义拟合LSTM模型的函数
def fit_lstm(data_prepare, n_neurons=50, n_batch=72, n_epoch=100, loss='mae', optimizer='adam', repeats=1):
    train_X = data_prepare[2]
    train_y = data_prepare[3]
    test_X = data_prepare[4]
    test_y = data_prepare[5]
    model_list = []
    for i in range(repeats):
        #设计神经网络
        model = Sequential()
        model.add(LSTM(n_neurons, input_shape=(train_X.shape[1], train_X.shape[2])))
        model.add(Dense(train_y.shape[0]))
        model.compile(loss=loss, optimizer=optimizer)
        #拟合神经网络
        history = model.fit(train_X, train_y, epochs=n_epoch, batch_size=n_batch, validation_data=(test_X, test_y), verbose=0, shuffle=False)
        #画出学习过程
        # 在训练数据上的损失
        p1 = pyplot.plot(history.history['loss'], color='blue', label='train')
        # 在测试数据上的损失
        p2 = pyplot.plot(history.history['val_loss'], color='yellow',label='test')
        #保存model
        model_list.append(model)
    pyplot.legend(["train","test"])
    pyplot.show()
    return model_list
```

