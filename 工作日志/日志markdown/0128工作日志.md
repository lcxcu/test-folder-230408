1. 对数据进行标准化后的模型拟合结果:
 损失值与MSE都有所减小，但模型仍表现略微过拟合。且模型似乎难以估计出那些在数据集上表现较为异常的点（尤其突出的点\盈收变化极快的点）
```python
训练集上损失值: 0.004951606038957834
训练集上MSE: 0.04608619213104248
测试集上损失值: 0.026254957541823387
测试集上MSE: 0.09266155958175659
```

下图中**红线**为真实值，**蓝线**为预测值
- **训练集**拟合结果图
![[train_fit.png]]

- **测试集**拟合结果图
![[test_fit.png]]
2. 第二层激活函数改用linear并选用优化器adam
```python
训练集上损失值: 0.0003491887473501265
训练集上MSE: 0.012626651674509048
测试集上损失值: 0.025147436186671257
测试集上MSE: 0.06638268381357193
```
- **训练集**拟合结果图
![[train_fit_2.png]]
- **测试集**拟合结果图
![[test_fit_2.png]]
当然还有以下方式改善模型过拟合，在数据源整合好之前还会继续尝试：
1.  使用 K 折交叉验证来评估模型性能和避免过拟合。
2.  使用正则化技巧，例如 L1 或 L2 正则化，来防止过拟合。
3.  尝试添加更多层或更多节点，以改进模型的准确性。
4.  尝试使用不同的损失函数，例如均方百分比误差或平均绝对误差。
5.  尝试使用 early stopping 来避免在训练过程中过拟合。
6.  数据集较大时, 可以考虑使用批量归一化来加速训练。

---
2. 复现数据来源的三个数据集compustat、crsp、IBES。
之前完成了compustat与crsp的数据库合并的尝试，但还需要将IBES的数据一同合并，已经在矩池云中尝试了，数据集较大，另外对矩池云中操作还不太熟悉 , 运行过程较慢，代码仍在调试。
