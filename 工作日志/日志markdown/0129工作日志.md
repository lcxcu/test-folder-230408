1. 在矩池云上运行了**所有股票数据**的拟合情况：

- 1. 训练集与测试集采用80%训练集，20%测试集
```python
训练集上损失值: 7.849442044971511e-05
训练集上MSE: 0.003331469837576151
测试集上损失值: 0.00010583338735159487
测试集上MSE: 0.0033522199373692274
```
训练集增加并没有让预测效果更好。
- 2. 取股票为900957进行测试，其余用于训练模型
```python
训练集上损失值: 8.47242699819617e-05
训练集上MSE: 0.003585822880268097
测试集上损失值: 6.959966412978247e-05
测试集上MSE: 0.0037051765248179436
```
相当的不拟合，预测出来是条直线。![[Pasted image 20230129225037.png]]

---
2. 模仿以下链接抑制模型过拟合
[tf.keras 04: 使用Keras判断和抑制过拟合](https://blog.csdn.net/weixin_39653948/article/details/105723407)
    [keras中的常用的损失函数](https://blog.csdn.net/miemieyang999/article/details/113372306)
**解决模型过拟合是现在模型性能好坏的关键**：
1. 定义优化器
在训练过程中逐渐降低学习速度，许多模型的训练效果会更好。
使用 `optimizers.schedules.InverseTimeDecay` 方法实现随着时间推移降低学习率：
```python
lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(
    0.001,
    decay_steps=len(y)/10,
    decay_rate=1,
    staircase=False)

def get_optimizer():
    return tf.keras.optimizers.Adam(lr_schedule)
    
# 绘制学习率图像
import matplotlib.pyplot as plt
step = np.linspace(0,len(y))
lr = lr_schedule(step)
plt.figure(figsize = (8,6), dpi=150)
plt.plot(step, lr)
plt.ylim([0,max(plt.ylim())])
plt.xlabel('Epoch')
plt.ylabel('Learning Rate')
```
![[learning rate.png]]
2. 模型编译和训练配置设置
```python
def compile_and_fit(model, name, optimizer=None, max_epochs=10000):
    
    if optimizer is None:
        optimizer = get_optimizer()
    
    model.compile(
        optimizer=optimizer,
        loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),
        metrics=[tf.keras.losses.BinaryCrossentropy(from_logits=True, name='binary_crossentropy'), 'accuracy'])

    model.summary()

    history = model.fit(
        train_ds,
        steps_per_epoch = STEPS_PER_EPOCH,
        epochs=max_epochs,
        validation_data=validate_ds,
        callbacks=get_callbacks(name),
        verbose=0)
    
    return history

```

思考可以加入[Multistep Time Series Forecasting with LSTMs in Python](https://machinelearningmastery.com/multi-step-time-series-forecasting-long-short-term-memory-networks-python/)的LSM深度学习模型。

3. 在矩池云进行数据连接：
- 三个数据集压缩后12G , 上传至网盘再到云池里解压，然后再运行数据连接。